{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharding Results\n",
    "\n",
    "Here we will analyze the results from [Flower](https://github.com/adap/flower) simulations for convergence on various datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "source": [
    "# Default\n",
    "import os\n",
    "import re\n",
    "import collections\n",
    "\n",
    "# File Utils\n",
    "import glob\n",
    "\n",
    "# Processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Simulation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "source": [
    "def simulation_files(simulation_dir: str, ext: str):\n",
    "    return glob.glob(f\"{simulation_dir}/*.{ext}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "source": [
    "def parse_filename(pattern: str, filename: str, default: str):\n",
    "    rs = re.search(pattern, filename)\n",
    "    if rs:\n",
    "        return rs.group(1) if rs.groups() else rs.group()\n",
    "    return default"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "source": [
    "simulation_path = \"../model\"\n",
    "ext = \"output\"\n",
    "\n",
    "simulation_filenames = simulation_files(simulation_dir=simulation_path, ext=ext)\n",
    "simulations = []\n",
    "for filename in simulation_filenames:\n",
    "    df_simulation = pd.read_csv(filename)\n",
    "\n",
    "    df_simulation[\"epoch\"] = df_simulation.index + 1\n",
    "    df_simulation[\"file\"] = os.path.basename(filename)\n",
    "    df_simulation[\"method\"] = df_simulation[\"file\"].apply(lambda x: parse_filename(r\"eval_([a-zA-Z0-9]+)_\", x, \"1\"))\n",
    "    df_simulation[\"B\"] = df_simulation[\"file\"].apply(lambda x: parse_filename(r\"B(\\d+)\", x, \"1\"))\n",
    "    df_simulation[\"E\"] = df_simulation[\"file\"].apply(lambda x: parse_filename(r\"E(\\d+)\", x, \"1\"))\n",
    "    simulations.append(df_simulation.apply(pd.to_numeric, errors=\"ignore\"))\n",
    "\n",
    "df_simulations = pd.concat(simulations).reset_index(drop=True)\n",
    "df_simulations"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "source": [
    "method_map = collections.defaultdict(lambda: \"UNKNOWN\", **{\n",
    "    \"SFL\": \"ScaleSFL\",\n",
    "    \"FAV\": \"FedAvg\"\n",
    "})"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "source": [
    "# Plot theming\n",
    "sns.set_theme(\"paper\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "source": [
    "df_data = df_simulations[df_simulations.method.str.len() > 1].sort_values(by=[\"method\", \"B\", \"E\"])\n",
    "legend = (\n",
    "    df_data.groupby(\"file\")\n",
    "    .head(1)\n",
    "    .sort_values(by=[\"method\", \"B\", \"E\"])\n",
    "    .apply(lambda x: f\"{method_map[x['method']]}: B={x['B']}, E={x['E']}\", axis=1)\n",
    ")\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 6))\n",
    "ax = sns.lineplot(\n",
    "    data=df_data, \n",
    "    x=\"epoch\", \n",
    "    y=\"loss\", \n",
    "    hue=\"file\",  \n",
    "    style=\"file\", \n",
    "    markers=True, dashes=False,\n",
    "    # legend=legend.tolist(), \n",
    "    # palette=sns.color_palette(\"hls\", as_cmap=True),\n",
    "    ax=axs[0]\n",
    ")\n",
    "ax.set(xlabel=\"# Global Epochs\", ylabel=\"Training Loss\")\n",
    "ax.legend(labels=legend)\n",
    "ax = sns.lineplot(\n",
    "    data=df_data, \n",
    "    x=\"epoch\", \n",
    "    y=\"accuracy\", \n",
    "    hue=\"file\",  \n",
    "    style=\"file\", \n",
    "    markers=True, dashes=False,\n",
    "    # legend=legend.tolist(), \n",
    "    # palette=sns.color_palette(\"hls\", as_cmap=True),\n",
    "    ax=axs[1]\n",
    ")\n",
    "ax.set(xlabel=\"# Global Epochs\", ylabel=\"Accuracy\")\n",
    "ax.legend(labels=legend)\n",
    "fig.tight_layout()\n",
    "ax.get_figure().savefig(\"model-performance.png\", dpi=300)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "feab6444362a055c4bb74576ac870b30db29940efba405683dcf987ba69cca2d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
